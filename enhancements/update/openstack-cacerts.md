---
title: openstack-cacert
authors:
  - "@stephenfin"
reviewers:
  - "@mdbooth"
  - "@mandre"
approvers:
  - "TBD"
api-approvers:
  - "None"
creation-date: 2025-03-19
last-updated: 2025-03-20
tracking-link:
  - https://issues.redhat.com/browse/OSASINFRA-3729
see-also:
  - "None"
replaces:
  - "None"
superseded-by:
  - "None"
---

# OpenStack CA Cert migration

## Summary

This enhancement proposes an update strategy for migrating the location of the
CA cert used for clusters deployed on OpenStack using self-signed certs.

## Motivation

OpenStack is frequently used as an on-prem cloud solution, and these
deployments often use self-signed certificates. As described in the
[installation guide][install-guide] a user can provide this during initial
installation by defining the `cacert` entry in their `clouds.yaml` file,
OpenStack's blessed format for credentials and related cloud configuration.

```yaml
clouds:
  shiftstack:
    # ...
    cacert: "/etc/openstack/shiftstack-ca.crt"
```

The Installer will then copy the CA cert from this file and use it to populate
the `openshift-config / cloud-provider-config` secret.

[install-guide]: https://docs.redhat.com/en/documentation/openshift_container_platform/4.18/html/installing_on_openstack/installing-openstack-installer-custom#installation-osp-describing-cloud-parameters_installing-openstack-installer-custom

There a number of issues with this approach, most notably the fact that this CA
cert is needed for all components that need to talk to the OpenStack cloud (CSI
drivers and driver operators, the OpenStack Machine API Provider (MAPO), the
Cluster Image Registry Operator, etc.). These components all run in different
namespaces, which means we need a variety of controllers to copy the CA cert to
namespace-specific config maps or create separate config maps and secrets,
which makes rotations a multi-step process. In addition, this config map-based
approach is not compatible with OpenStack-specific components like the
OpenStack CAPI Provider (CAPO) and OpenStack Resource Controller (ORC), which
both expect the CA cert to be provided in the credential secret.

- `machine-api-provider-openstack` has a controller that fetches the cert
  from `openshift-config / cloud-provider-config`, as seen [here][source-mapo]

- `csi-operator` has controller for both [Cinder CSI][source-cinder] and
  [Manila CSI][source-manila] that do the same. Of these, the Cinder one is by
  far the more complicated since it copies and transforms the source config map
  into another config map in the `openshift-cluste-csi-drivers` namespace.

- `cluster-image-registry-operator` also has [a controller][source-ciro]

- `cloud-network-config-controller` is using a [controller][source-cncc] but
  one that inspects a different config map, `openshift-config-managed /
  kube-cloud-config`, which is generated by `cluster-config-operator` as seen
  [here][source-cco] yet isn't used elsewhere...

- CAPO (as deployed by `cluster-capi-operator`) and ORC are both currently
  broken on clouds using self-signed certs

[source-mapo]: https://github.com/openshift/machine-api-provider-openstack/blob/d2fce230a2df0cf3b47769f0118d6475f796cb35/pkg/clients/utils.go#L51-L64
[source-cinder]: https://github.com/openshift/csi-operator/blob/ef6c98a43953f182f9fb405128c91d3c1c6144ef/pkg/openstack-cinder/config/configsync.go#L172-L180
[source-manila]: https://github.com/openshift/csi-operator/blob/ef6c98a43953f182f9fb405128c91d3c1c6144ef/pkg/driver/openstack-manila/openstack_manila.go#L343-L365
[source-ciro]: https://github.com/openshift/cluster-image-registry-operator/blob/f27308c19e654021b614b12505b298315a72135c/pkg/storage/swift/swift.go#L176-L189
[source-cncc]: https://github.com/openshift/cloud-network-config-controller/blob/5985f3b31274c555b32ac59aa0dfcbca877a3235/cmd/cloud-network-config-controller/main.go#L200-L224
[source-cco]: https://github.com/openshift/cluster-config-operator/blob/cbfd00a8204d5ae5d755edf05b7c26a60218a9b7/pkg/operator/kube_cloud_config/controller.go#L113-L132

In [OSASINFRA-3729](https://issues.redhat.com/browse/OSASINFRA-3729), we have
proposed resolving these issues by making the CA cert part of the credential
secret managed by Cloud Credential Operator (CCO). CCO provides the ability to
copy a set of credentials from a well-known location (`kube-system /
openstack-credentials` for OpenStack) to a namespace by creating a
`CredentialsRequest`. CCO previously managed a single field, `clouds.yaml`,
which contained OpenStack credentials in the typical format (note that there is
also an additional field, `clouds.conf`, which was used to configure the legacy
in-tree CCM and is still being added by the Installer, but CCO ignores this).
With this change, CCO now manages a new `cacert` key, copying this to the
credentials secrets created in response to `CredentialsRequest` CRs. This
allows us to simplify a lot of operators by removing the config map syncers
they currently have as well as removing a split between standalone and
hypershift deployments due to differences in config map naming. However,
because of CCM's role in bootstrapping in OpenShift, we cannot rely on
CCO-managed credentials (tl;dr: CCM comes up before CCO does and needs to talk
to the cloud so that it can get instances to deploy pods on). This means we
cannot remove the CA cert from the CCM-specific config map. However, we do not
want CA cert rotation to involve updating multiple locations..

The dumb solution is to introduce a controller that will either copy the CA
cert from the credential secret to the CCM config map or vice versa. However,
this poses an issue for tooling. If we copy from the credential secret to the
CCM config map, we break hypothetical tooling that is updating the config map,
since all changes to this config map will be overridden. If we copy from the
CCM config map to the credential secret, we prevent new tooling being written
that targets the credential secret since, again, any changes will be
overwritten. We need to find a solution that allow existing tooling to continue
to work for some transition period, while also allowing tooling that uses the
new location to be written.

### User Stories

* As an OpenShift administrator, I want to be able to rotate the CA cert used
  for my cloud as easily as I can rotate my credentials.
* As an OpenShift administrator, I want to continue using my existing CA cert
  rotation scripts for a transition period.

### Goals

* Provide a clear upgrade path for migrating from the "old" way to the "new"
  way that doesn't break existing tooling

### Non-Goals

* Re-litigate having CCO manage the CA cert for us rather than using
  `additionalTrustBundle` and `additionalTrustBundlePolicy = Always`.

  In brief, this approach doesn't address any of our issues for CAPO and ORC,
  would have an even larger upgrade impact, and has a variety of other
  shortcomings that led to current CCM config map-based approach we used.

## Proposal

This enhance proposes to handle upgrades using a syncing controller than adds
hash annotations on the root credential secret and CCM config map. The initial
logic, implemented e.g. via an init container, will work like so:

* If neither the CA cert field of the secret (new location) nor the CA cert
  field of the config map (old location) are populated, do nothing.
* If only the old location is populated, compute a hash of the value and then
  copy the value to the new location. Once copied, set an annotation in both
  places corresponding to the hash.
* If only the new location is populated, compute a hash of the value and then
  copy the value to the old location. Once copied, set an annotation in both
  places corresponding to the hash. **NOTE** This should never happen as the
  installer will always populate the old location when a CA cert is required
  due to the aforementioned bootstrapping issues. However, we will handle it
  just in case.

Once this initial step has completed, the controller will continuously run and
do the following on ever reconciliation loop:

1. Read the CA cert and stored hash from both locations.
2. Compare the hashes:
   * If the hashes match, no action is required.
   * If the hashes match one source (a) but not the other (b), this indicates
     that the value in the other location (b) was changed and we need to
     recalculate the hashes and update (a).
    * If the hashes don't match either source, it could mean that the user
      updated both locations concurrently. In this case, we set the controller
      to degraded and do not overwrite anything.

### Workflow Description

Given a cluster administrator and a working standalone cluster for which the
administrator is responsible.

**Cluster administrator** is a human user responsible for managing the cluster.

1. The cluster administrator chooses to update their CA cert. They run their
   existing tooling and everything just works (TM).
2. At a later date, the cluster administrator reads the release notes and
   realises that they need to update their tooling. They do so and then run the
   new tooling. Everything continues to just work (TM).

### API Extensions

None.

### Topology Considerations

#### Hypershift / Hosted Control Planes

None. Hypershift does not CCO. We can handle syncing these in the Hypershift
Operator.

#### Standalone Clusters

None. Changes may be necessary to external tooling.

#### Single-node Deployments or MicroShift

Same as standalone clusters.

### Implementation Details/Notes/Constraints

None

### Risks and Mitigations

The risk of getting this wrong is that we break existing tooling. We are not
aware of such tooling, but we're proposing this enhancment out of an abundance
of caution.

### Drawbacks

No drawbacks are known.

## Open Questions [optional]

No open questions.

## Test Plan

* Manual testing.

## Graduation Criteria

### Dev Preview -> Tech Preview

Not applicable.

### Tech Preview -> GA

Not applicable.

### Removing a deprecated feature

Not applicable.

## Upgrade / Downgrade Strategy

Not applicable.

## Version Skew Strategy

Not applicable.

## Operational Aspects of API Extensions

Not applicable.

## Support Procedures

Not applicable.

## Alternatives

### Require admin ack during upgrades

We treat this change like an API change and note it in the release notes, then
require the admin to patch the `openshift-config / admin-acks` config map.

## Infrastructure Needed [optional]

No new infrastructure is needed.
